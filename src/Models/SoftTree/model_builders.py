"""Model Builder functions

    = common model configurations
"""
import tensorflow as tf
import numpy.random as npr
from Models.SoftTree.layers import LayerFactoryIface, var_construct
from Models.SoftTree.forest import build_forest
from Models.SoftTree.decoders import GaussFull

# TODO: interface


# TODO: implement interface
class GMMforest:

    def __init__(self, depth: int, layer_factory: LayerFactoryIface,
                    num_mix: int, gauss_dim: int, rng: npr.Generator):
        self.soft_forest, self.width = build_forest(depth, layer_factory)
        self.num_state = int(self.width ** depth)
        self.num_model = layer_factory.get_num_models()
        self.num_mix = num_mix
        self.gauss_dim = gauss_dim
        self.decoder = GaussFull(layer_factory.get_num_models(),
                                    self.num_state * num_mix,
                                    gauss_dim, rng)
        # variable for mixing coeffs: num_model x num_state x num_mixture
        self.mix_coeffs = tf.nn.softmax(var_construct(rng, [layer_factory.get_num_models(),
                                                            self.num_state, num_mix]), axis=-1)
    
    # TODO: probably need some prediction methods
    # > predict state? > predict average rep???

    # TODO: have to make this interface work with tfrecords stuff
    def loss(self, x, y, data_weights):
        """Loss function

        Args:
            x (tf.tensor or List[tf.tensor]): input ~ must match shape
                generated by layer_factory
            y (tf.tensor): target/truth ~ batch_size x 
            data_weights (tf.tensor): weights on the data points
                batch_size x num_model
        """
        # scales:
        dw = tf.expand_dims(data_weights, 2)
        dw = tf.expand_dims(data_weights, 2)
        # --> batch_size x num_model x num_state x num_mix
        weights = (tf.expand_dims(self.soft_forest.eval(x), 3) * tf.expand_dims(self.mix_coeffs, 0)
                        * dw)

        # log-likes of each gaussian:
        # --> batch_size x num_model x (num_state * num_mix)
        ll = self.decoder.calc_log_prob(y)
        ll_res = tf.reshape(ll, [-1, self.num_model, self.num_state, self.num_mix])
    
        # negate for loss:
        return -1 * tf.reduce_sum(weights * ll_res)
